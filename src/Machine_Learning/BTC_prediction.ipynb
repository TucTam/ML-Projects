{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c6f8fa1-7136-42ec-9c50-c7c4629aa6a9",
   "metadata": {},
   "source": [
    "# BTC PRICE ESTIMATING ML MODEL\n",
    "## Description\n",
    "This is a machine learning model that estimates the bitcoin closing price, according to the dates, closing price, and volumes.\n",
    "The model architechture is a feed forward model\n",
    "- Loss function: MSELoss\n",
    "- Optimizer: Adam\n",
    "- Num of hidden layers 3\n",
    "- input layer size = 8\n",
    "- output layer size = 1\n",
    "- Activation function: ReLU\n",
    "- output activation = None\n",
    "\n",
    "## Model Evaluation\n",
    "- This model is evaluated using R2Score\n",
    "\n",
    "## Dataset\n",
    "- Dataset is sourced from kaggle: https://www.kaggle.com/datasets/aski1140/bitcoin-prices-minutes-2020-2024\n",
    "- For this model we used the prices from 01.01.2020-31.12.2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6343d1b6-87cd-42e6-982a-dd164dcac36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries/modules/functions\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torchmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d863c7cd-0b39-46de-963f-c6a44910feab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Defining  on which device to run the model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "11349471-2e58-454f-857e-4d6aadd0eb8e",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../../datasets/Binance_BTCUSDT_2020_minute.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Data preprocessing (cleaning, changing datatypes, adding variables, etc)\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../../datasets/Binance_BTCUSDT_2020_minute.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mS\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      5\u001b[0m data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myear\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39myear\n",
      "File \u001b[1;32mE:\\Anaconda3\\envs\\dataml100\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32mE:\\Anaconda3\\envs\\dataml100\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mE:\\Anaconda3\\envs\\dataml100\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[1;32mE:\\Anaconda3\\envs\\dataml100\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m   1881\u001b[0m     f,\n\u001b[0;32m   1882\u001b[0m     mode,\n\u001b[0;32m   1883\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1884\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1885\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m   1886\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[0;32m   1887\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1888\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1889\u001b[0m )\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32mE:\\Anaconda3\\envs\\dataml100\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    874\u001b[0m             handle,\n\u001b[0;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    876\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    877\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    879\u001b[0m         )\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../../datasets/Binance_BTCUSDT_2020_minute.csv'"
     ]
    }
   ],
   "source": [
    "# Data preprocessing (cleaning, changing datatypes, adding variables, etc)\n",
    "data = pd.read_csv(\"../../datasets/Binance/Binance_BTCUSDT_2020_minute.csv\")\n",
    "data[\"date\"] = pd.to_datetime(data[\"date\"], format='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "data[\"year\"] = data[\"date\"].dt.year\n",
    "data[\"month\"] = data[\"date\"].dt.month\n",
    "data[\"day\"] = data[\"date\"].dt.day\n",
    "data[\"hour\"] = data[\"date\"].dt.hour\n",
    "data[\"minute\"] = data[\"date\"].dt.minute\n",
    "data.drop(columns=['date'])\n",
    "\n",
    "# Reversing the data so that the oldest is the first row and the newest is the last row\n",
    "data = data.iloc[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e30f93-9a79-40ed-9e4c-93a19fcc8023",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the features and labels\n",
    "features = data.iloc[:, [10,11,12,13,14,3,7,8]]\n",
    "labels = data.iloc[:, 6]\n",
    "# Scaling the data and reshaping them into proper forms\n",
    "scaler = StandardScaler()\n",
    "features = scaler.fit_transform(features.to_numpy(\"float32\"))\n",
    "labels = scaler.fit_transform(labels.to_numpy(\"float32\").reshape(-1,1))\n",
    "\n",
    "# Turning them into tensors\n",
    "features = torch.tensor(features)\n",
    "labels = torch.tensor(labels).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "19d1f152-9401-49c5-af10-3633442d288a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[0;32m      3\u001b[0m batchsize \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m\n\u001b[1;32m----> 4\u001b[0m inputsz \u001b[38;5;241m=\u001b[39m features\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m      5\u001b[0m h1size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m16\u001b[39m\n\u001b[0;32m      6\u001b[0m h2size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m16\u001b[39m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'features' is not defined"
     ]
    }
   ],
   "source": [
    "# Defining hyperparameters\n",
    "epochs = 2\n",
    "batchsize = 100\n",
    "inputsz = features.shape[1]\n",
    "h1size = 16\n",
    "h2size = 16\n",
    "h3size = 16\n",
    "outsz = labels.shape[1]\n",
    "learning_rate = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d5a0cdc8-8f6f-4fbb-95ed-bd6c474851ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating custom dataset class that inherits Dataset module\n",
    "class BTCdataset(Dataset):\n",
    "    def __init__(self, features, labels):\n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "\n",
    "    # Returns the length of the dataset (the num of rows/samples)\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    # Returns the feature row, and the label at the index location\n",
    "    def __getitem__(self, idx):\n",
    "        input = self.features[idx]\n",
    "        label = self.labels[idx]\n",
    "        return input, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d06fe688-ec56-451c-bc90-eedff745a295",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Splitting our data into training and testing sets\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m xtrain, xtest, ytrain, ytest \u001b[38;5;241m=\u001b[39m train_test_split(features, labels, train_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.8\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Initializing our custom dataset class, which is then used to initialize DataLoader class\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Dataloader class is what is used to train and test our model\u001b[39;00m\n\u001b[0;32m      6\u001b[0m traindb \u001b[38;5;241m=\u001b[39m BTCdataset(xtrain,ytrain)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'features' is not defined"
     ]
    }
   ],
   "source": [
    "# Splitting our data into training and testing sets\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(features, labels, train_size=0.8)\n",
    "\n",
    "# Initializing our custom dataset class, which is then used to initialize DataLoader class\n",
    "# Dataloader class is what is used to train and test our model\n",
    "traindb = BTCdataset(xtrain,ytrain)\n",
    "testdb = BTCdataset(xtest, ytest)\n",
    "\n",
    "# Init. dataloader with batchsize and shuffle, etc specifications\n",
    "trainloader = DataLoader(traindb, batch_size=batchsize, shuffle=False)\n",
    "testloader = DataLoader(testdb, batch_size=batchsize, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e804a41d-3df2-4567-8b62-8c8f8ad19e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating our model architecture\n",
    "class BTCpredictor(nn.Module):\n",
    "    def __init__(self, input_sz, hid1, hid2, hid3, outsize, activation=nn.ReLU()):\n",
    "        super(BTCpredictor, self).__init__()\n",
    "        self.sequential = nn.Sequential(\n",
    "            nn.Linear(input_sz, hid1),\n",
    "            activation,\n",
    "            nn.Linear(hid1, hid2),\n",
    "            activation,\n",
    "            nn.Linear(hid2, hid3),\n",
    "            activation,\n",
    "            nn.Linear(hid3, outsize)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        output = self.sequential(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7aaf9003-6961-4a9a-a699-e6eaa0971b19",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'inputsz' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Initializing our model, loss function, activation function\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m model \u001b[38;5;241m=\u001b[39m BTCpredictor(inputsz, h1size, h2size, h3size, outsz)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m      4\u001b[0m criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mMSELoss()\n\u001b[0;32m      5\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), learning_rate)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'inputsz' is not defined"
     ]
    }
   ],
   "source": [
    "# Initializing our model, loss function, activation function\n",
    "model = BTCpredictor(inputsz, h1size, h2size, h3size, outsz).to(device)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "77921aca-0270-4496-b4f2-880395a5fe97",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Training the model\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m inputs, label \u001b[38;5;129;01min\u001b[39;00m trainloader:\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# Training the model\n",
    "model.train()\n",
    "for epoch in range(epochs):\n",
    "    for inputs, label in trainloader:\n",
    "        optimizer.zero_grad()\n",
    "        inputs = inputs.to(device)\n",
    "        label = label.to(device)\n",
    "\n",
    "        output = model(inputs)\n",
    "        loss = criterion(output, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(f\"MSEloss: {loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "af0e423e-0332-4276-af72-d106cd7466db",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Evaluating the model\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Initializing the metric\u001b[39;00m\n\u001b[0;32m      5\u001b[0m R2metric \u001b[38;5;241m=\u001b[39m torchmetrics\u001b[38;5;241m.\u001b[39mR2Score()\u001b[38;5;241m.\u001b[39mto(device)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# Evaluating the model\n",
    "model.eval()\n",
    "\n",
    "# Initializing the metric\n",
    "R2metric = torchmetrics.R2Score().to(device)\n",
    "\n",
    "predicted = []\n",
    "actuals = []\n",
    "x_values = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for input, label in testloader:\n",
    "        input = input.to(device)\n",
    "        label = label.to(device)\n",
    "\n",
    "        out = model(input)\n",
    "        predicted.extend(out.cpu().numpy())\n",
    "        actuals.extend(label.cpu().numpy())\n",
    "        x_values.extend(input[:,0].cpu().numpy())\n",
    "        # Update R2 metric with predictions and true labels\n",
    "        R2metric.update(out, label)\n",
    "\n",
    "R2score = R2metric.compute()\n",
    "print(f\"R2 Score: {R2score:.4f}\")\n",
    "\n",
    "R2metric.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0e256c05-3a12-4e66-b8e4-6c2868222799",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'testloader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Checking a single sample test\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m----> 3\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28minput\u001b[39m, label \u001b[38;5;129;01min\u001b[39;00m testloader:\n\u001b[0;32m      4\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m      5\u001b[0m         label \u001b[38;5;241m=\u001b[39m label\u001b[38;5;241m.\u001b[39mto(device)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'testloader' is not defined"
     ]
    }
   ],
   "source": [
    "# Checking a single sample test\n",
    "with torch.no_grad():\n",
    "    for input, label in testloader:\n",
    "        input = input.to(device)\n",
    "        label = label.to(device)\n",
    "        out = model(input)\n",
    "        print(f\"prediction: {out[0]}\\n actual: {label[0]}\")\n",
    "        if True: break\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d7874aec-0711-4d5e-8f73-a68d507f808c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'scaler' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Plotting the testing results:\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m predicted \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39minverse_transform(predicted)\n\u001b[0;32m      3\u001b[0m actuals \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39minverse_transform(actuals)\n\u001b[0;32m      4\u001b[0m x_values \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39minverse_transform(np\u001b[38;5;241m.\u001b[39masarray(x_values)\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'scaler' is not defined"
     ]
    }
   ],
   "source": [
    "# Plotting the testing results:\n",
    "predicted = scaler.inverse_transform(predicted)\n",
    "actuals = scaler.inverse_transform(actuals)\n",
    "x_values = scaler.inverse_transform(np.asarray(x_values).reshape(-1,1))\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(actuals[:100], label=\"actual values\", color=\"blue\")\n",
    "plt.plot(predicted[:100], label = \"predicted values\", color=\"red\")\n",
    "plt.xlabel(\"steps\")\n",
    "plt.ylabel(\"Prices\")\n",
    "plt.title(\"actual vs predicted BTC prices\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe8fc2b-eb3d-408e-8ca8-e501bd0bb4a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
